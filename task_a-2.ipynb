{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install textblob\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Antd0llxAq7k",
        "outputId": "a126f094-60b9-48ff-de0e-c6d6522c29b3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: textblob in /usr/local/lib/python3.10/dist-packages (0.17.1)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.10/dist-packages (from textblob) (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (4.66.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install spellchecker"
      ],
      "metadata": {
        "id": "rOTK5JKWRj19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install textstat"
      ],
      "metadata": {
        "id": "qshuGT1JRlN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "L6GkIxWWnw_7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import regex as re\n",
        "from textstat.textstat import textstat\n",
        "from textblob import TextBlob\n",
        "from spellchecker import SpellChecker\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8ZqZHdek9Kgh"
      },
      "outputs": [],
      "source": [
        "sns.set_theme(style=\"whitegrid\")\n",
        "\n",
        "# Main Dataset\n",
        "\n",
        "# Conversation Data -- we will use this data in the \"Conversation Data\" section\n",
        "\n",
        "sentiment_df = pd.read_json(\n",
        "    \"sentiment_scores.json\",\n",
        "    lines=True\n",
        ")\n",
        "\n",
        "\n",
        "# Topic Modeling and Hardness Score Data -- we will use this data in the \"Topic Modeling and Hardness Score Data\" section\n",
        "topic_and_hardness = pd.read_json(\n",
        "    \"chatbot-arena-gpt3-scores.jsonl.gz\",\n",
        "    lines=True,\n",
        "    compression=\"gzip\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "svHqTq-Yq11S"
      },
      "outputs": [],
      "source": [
        "# Embedding Data -- we will use this data in the \"Embedding Data\" section\n",
        "prompt_embeddings = np.load(\n",
        "    \"chatbot-arena-prompts-embeddings.npy\"\n",
        ")\n",
        "\n",
        "response_a_embeddings = np.load(\n",
        "    \"chatbot-arena-model_a_response-embeddings.npy\"\n",
        ")\n",
        "\n",
        "response_b_embeddings = np.load(\n",
        "    \"chatbot-arena-model_b_response-embeddings.npy\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0CowMoRyE6_",
        "outputId": "de36546f-37d0-484b-ea7e-2923d3883806"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'RWKV-4-Raven-14B': '1000000000000000000000', 'alpaca-13b': '0100000000000000000000', 'chatglm-6b': '0010000000000000000000', 'claude-instant-v1': '0001000000000000000000', 'claude-v1': '0000100000000000000000', 'dolly-v2-12b': '0000010000000000000000', 'fastchat-t5-3b': '0000001000000000000000', 'gpt-3.5-turbo': '0000000100000000000000', 'gpt-4': '0000000010000000000000', 'gpt4all-13b-snoozy': '0000000001000000000000', 'guanaco-33b': '0000000000100000000000', 'koala-13b': '0000000000010000000000', 'llama-13b': '0000000000001000000000', 'mpt-7b-chat': '0000000000000100000000', 'oasst-pythia-12b': '0000000000000010000000', 'palm-2': '0000000000000001000000', 'stablelm-tuned-alpha-7b': '0000000000000000100000', 'vicuna-13b': '0000000000000000010000', 'vicuna-7b': '0000000000000000001000', 'wizardlm-13b': '0000000000000000000100', 'tie': '0000000000000000000010', 'tie(bothbad)': '0000000000000000000001'}\n"
          ]
        }
      ],
      "source": [
        "# convert names of models a and b to one hot encodings\n",
        "categories = [\n",
        "    'RWKV-4-Raven-14B', 'alpaca-13b', 'chatglm-6b', 'claude-instant-v1', 'claude-v1',\n",
        "    'dolly-v2-12b', 'fastchat-t5-3b', 'gpt-3.5-turbo', 'gpt-4', 'gpt4all-13b-snoozy',\n",
        "    'guanaco-33b', 'koala-13b', 'llama-13b', 'mpt-7b-chat', 'oasst-pythia-12b',\n",
        "    'palm-2', 'stablelm-tuned-alpha-7b', 'vicuna-13b', 'vicuna-7b', 'wizardlm-13b', 'tie', 'tie(bothbad)'\n",
        "]\n",
        "\n",
        "one_hot_dict = {}\n",
        "\n",
        "for idx, category in enumerate(categories):\n",
        "    one_hot_vector = [0] * len(categories)\n",
        "    one_hot_vector[idx] = 1\n",
        "    one_hot_dict[category] = ''.join(map(str, one_hot_vector))\n",
        "\n",
        "print(one_hot_dict)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "JLR1nqpiMM-e"
      },
      "outputs": [],
      "source": [
        "#add a new column that displays the name of the winning chatbot model (or tie)\n",
        "sentiment_df['winner_model'] = np.where(\n",
        "    sentiment_df['winner'] == 'model_b', sentiment_df['model_b'],\n",
        "    np.where(\n",
        "        sentiment_df['winner'] == 'model_a', sentiment_df['model_a'],\n",
        "        np.where(\n",
        "            sentiment_df['winner'] == 'tie', 'tie', 'tie(bothbad)'\n",
        "        )\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "7qKgAX6wyeE6"
      },
      "outputs": [],
      "source": [
        "#replace model names in model_a and model_b with onehot encodings\n",
        "sentiment_df['winner_model'] = sentiment_df['winner_model'].map(one_hot_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "NXHu2ORKX_dp"
      },
      "outputs": [],
      "source": [
        "# Find cosine similarity of prompt embeddings\n",
        "# Takes about a minute to run\n",
        "response_a_prompt_similarity = np.array([\n",
        "    cosine_similarity(response_a_embeddings[i].reshape(1, -1), prompt_embeddings[i].reshape(1, -1))[0, 0]\n",
        "    for i in range(len(sentiment_df))\n",
        "])\n",
        "response_b_prompt_similarity = np.array([\n",
        "    cosine_similarity(response_b_embeddings[i].reshape(1, -1), prompt_embeddings[i].reshape(1, -1))[0, 0]\n",
        "    for i in range(len(sentiment_df))\n",
        "])\n",
        "response_ab_similarity = np.array([\n",
        "    cosine_similarity(response_a_embeddings[i].reshape(1,-1), response_b_embeddings[i].reshape(1, -1))[0,0]\n",
        "    for i in range(len(sentiment_df))\n",
        "])\n",
        "\n",
        "sentiment_df['a_prompt_text_similarity'] = response_a_prompt_similarity\n",
        "sentiment_df['b_prompt_text_similarity'] = response_b_prompt_similarity\n",
        "sentiment_df['ab_text_similarity'] = response_ab_similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "YoScmuTTtgKC"
      },
      "outputs": [],
      "source": [
        "#function to extract numeric score from sentiment columns\n",
        "def process_sentiment(sentiment):\n",
        "    sentiment_dict = sentiment[0]\n",
        "    score = sentiment_dict['score']\n",
        "    if sentiment_dict['label'] == 'NEGATIVE':\n",
        "        return -score\n",
        "    return score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Fd9sIbA8tlhx"
      },
      "outputs": [],
      "source": [
        "sentiment_df['prompt_sentiment_score'] = sentiment_df['prompt_sentiment'].apply(process_sentiment)\n",
        "sentiment_df['response_a_sentiment_score'] = sentiment_df['response_a_sentiment'].apply(process_sentiment)\n",
        "sentiment_df['response_b_sentiment_score'] = sentiment_df['response_b_sentiment'].apply(process_sentiment)\n",
        "sentiment_df.drop(columns=['prompt_sentiment'], inplace=True)\n",
        "sentiment_df.drop(columns=['response_a_sentiment'], inplace=True)\n",
        "sentiment_df.drop(columns=['response_b_sentiment'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "pIAH84-JvK7U",
        "outputId": "7cc1ed90-149d-4a3d-8542-58e8cfcb4bb0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "prompt_sentiment_score        0\n",
              "response_a_sentiment_score    0\n",
              "response_b_sentiment_score    0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>prompt_sentiment_score</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>response_a_sentiment_score</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>response_b_sentiment_score</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "sentiment_df[['prompt_sentiment_score', 'response_a_sentiment_score', 'response_b_sentiment_score']].isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "RJlKOsGlu8v6"
      },
      "outputs": [],
      "source": [
        "#find the difference in sentiment scores between model a and b and between prompt and responses\n",
        "sentiment_df[\"prompt_a_sentiment_diff\"] = sentiment_df[\"prompt_sentiment_score\"] - sentiment_df[\"response_a_sentiment_score\"]\n",
        "sentiment_df[\"prompt_b_sentiment_diff\"] = sentiment_df[\"prompt_sentiment_score\"] - sentiment_df[\"response_b_sentiment_score\"]\n",
        "sentiment_df[\"ab_sentiment_diff\"] = sentiment_df[\"response_a_sentiment_score\"] - sentiment_df[\"response_b_sentiment_score\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "pfBS5237tLAh"
      },
      "outputs": [],
      "source": [
        "search_words = [\"can't\", \"won't\", \"will not\", \"cannot\", \"sorry\"]\n",
        "def contains_negation(response, target_words):\n",
        "    response = response.lower()  # Convert the response to lowercase\n",
        "    for word in target_words:\n",
        "        if word.lower() in response:\n",
        "            return 1\n",
        "    return 0\n",
        "sentiment_df[\"response_a_contains_negation\"] = sentiment_df[\"model_a_response\"].apply(\n",
        "    lambda x: contains_negation(x, search_words)\n",
        ")\n",
        "sentiment_df[\"response_b_contains_negation\"] = sentiment_df[\"model_b_response\"].apply(\n",
        "    lambda x: contains_negation(x, search_words)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "2Qy9dz7sv58T"
      },
      "outputs": [],
      "source": [
        "#create one hot encoded features to look for auxiliary verbs in each response\n",
        "modal_verbs = ['can', 'could', 'may', 'might', 'shall', 'should', 'will', 'would', 'must', 'have to']\n",
        "\n",
        "# Function to create one-hot encoded columns for modal verbs\n",
        "def encode_modal_verbs(df, model_a_col, model_b_col, modal_verbs):\n",
        "    for verb in modal_verbs:\n",
        "        # Create regex pattern for the verb\n",
        "        pattern = rf'\\b{re.escape(verb)}\\b'\n",
        "\n",
        "        # Create one-hot encoded column for model_a_response\n",
        "        df[f'modal_a_{verb}'] = df[model_a_col].str.contains(pattern, case=False, na=False).astype(int)\n",
        "\n",
        "        # Create one-hot encoded column for model_b_response\n",
        "        df[f'modal_b_{verb}'] = df[model_b_col].str.contains(pattern, case=False, na=False).astype(int)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "sentiment_df = encode_modal_verbs(sentiment_df, 'model_a_response', 'model_b_response', modal_verbs)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#search for \"for example\" in responses\n",
        "def encode_examples(df, model_a_col, model_b_col):\n",
        "    example_pattern = r'\\bfor example\\b'\n",
        "    df['contains_example_a'] = df[model_a_col].str.contains(example_pattern, case=False, na=False).astype(int)\n",
        "    df['contains_example_b'] = df[model_b_col].str.contains(example_pattern, case=False, na=False).astype(int)\n",
        "\n",
        "    return df\n",
        "\n",
        "sentiment_df = encode_examples(sentiment_df, 'model_a_response', 'model_b_response')"
      ],
      "metadata": {
        "id": "WHktkNTU_WOY"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "qLa9iAN75Yt_"
      },
      "outputs": [],
      "source": [
        "#analyze response readability with textstat\n",
        "sentiment_df['response_a_readability'] = sentiment_df['model_a_response'].apply(lambda x: textstat.flesch_reading_ease(str(x)))\n",
        "sentiment_df['response_b_readability'] = sentiment_df['model_b_response'].apply(lambda x: textstat.flesch_reading_ease(str(x)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "UXzx9B6dNNWt"
      },
      "outputs": [],
      "source": [
        "sentiment_df['response_readability_diff'] = sentiment_df['response_a_readability'] - sentiment_df['response_b_readability']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "3TIkxWezojM4"
      },
      "outputs": [],
      "source": [
        "#create columns for prompt and response lengths\n",
        "sentiment_df[\"prompt_length\"] = sentiment_df[\"prompt\"].str.len()\n",
        "sentiment_df[\"response_a_length\"] = sentiment_df[\"model_a_response\"].str.len()\n",
        "sentiment_df[\"response_b_length\"] = sentiment_df[\"model_b_response\"].str.len()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "u9XCwe4rurR9"
      },
      "outputs": [],
      "source": [
        "#create features to compare prompt an response length as well as lengths of responses a and b\n",
        "sentiment_df[\"prompt_minus_response_a_length\"] = sentiment_df[\"prompt_length\"] - sentiment_df[\"response_a_length\"]\n",
        "sentiment_df[\"prompt_minus_response_b_length\"] = sentiment_df[\"prompt_length\"] - sentiment_df[\"response_b_length\"]\n",
        "sentiment_df[\"response_a_minus_response_b_length\"] = sentiment_df[\"response_a_length\"] - sentiment_df[\"response_b_length\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "_d7oPINNtddW"
      },
      "outputs": [],
      "source": [
        "# Initialize Elo ratings for all models\n",
        "elo_ratings = {model: 1000 for model in pd.concat([sentiment_df[\"model_a\"], sentiment_df[\"model_b\"]]).unique()}\n",
        "\n",
        "def calculate_elo_ratings(df, k=32):\n",
        "    \"\"\"\n",
        "    Calculate and update Elo ratings for model_a and model_b for each row.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): DataFrame containing 'model_a', 'model_b', and 'winner' columns.\n",
        "        k (int): The K-factor to control the adjustment magnitude.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Updated DataFrame with Elo ratings for model_a and model_b at each row.\n",
        "    \"\"\"\n",
        "    # Create columns to store Elo ratings\n",
        "    df['model_a_elo'] = 0.0\n",
        "    df['model_b_elo'] = 0.0\n",
        "\n",
        "    # Loop through rows\n",
        "    for idx, row in df.iterrows():\n",
        "        model_a = row['model_a']\n",
        "        model_b = row['model_b']\n",
        "        winner = row['winner']\n",
        "\n",
        "        # Current ratings\n",
        "        rating_a = elo_ratings[model_a]\n",
        "        rating_b = elo_ratings[model_b]\n",
        "\n",
        "        # Calculate expected scores\n",
        "        expected_a = 1 / (1 + 10 ** ((rating_b - rating_a) / 400))\n",
        "        expected_b = 1 - expected_a\n",
        "\n",
        "        # Update ratings based on the winner\n",
        "        if winner == \"model_a\":\n",
        "            elo_ratings[model_a] += k * (1 - expected_a)\n",
        "            elo_ratings[model_b] += k * (0 - expected_b)\n",
        "        elif winner == \"model_b\":\n",
        "            elo_ratings[model_a] += k * (0 - expected_a)\n",
        "            elo_ratings[model_b] += k * (1 - expected_b)\n",
        "\n",
        "        # update df\n",
        "        df.at[idx, 'model_a_elo'] = elo_ratings[model_a]\n",
        "        df.at[idx, 'model_b_elo'] = elo_ratings[model_b]\n",
        "\n",
        "    return df\n",
        "\n",
        "# Find difference in ELO rating for each row\n",
        "sentiment_df = calculate_elo_ratings(sentiment_df)\n",
        "\n",
        "sentiment_df['model_a_elo_change'] = sentiment_df['model_a_elo'].diff()\n",
        "sentiment_df['model_b_elo_change'] = sentiment_df['model_b_elo'].diff()\n",
        "sentiment_df.at[0, 'model_a_elo_change'] = -16\n",
        "sentiment_df.at[0, 'model_b_elo_change'] = 16\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "b74eR4eduEEb"
      },
      "outputs": [],
      "source": [
        "#convert hardness scores to int so that we can find the mean\n",
        "topic_and_hardness['score_value_1'] = pd.to_numeric(topic_and_hardness['score_value_1'], errors='coerce')\n",
        "topic_and_hardness['score_value_2'] = pd.to_numeric(topic_and_hardness['score_value_2'], errors='coerce')\n",
        "topic_and_hardness['score_value_3'] = pd.to_numeric(topic_and_hardness['score_value_3'], errors='coerce')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "8r0lk1cdB_NQ"
      },
      "outputs": [],
      "source": [
        "topic_and_hardness['hardness_score'] = topic_and_hardness[['score_value_1', 'score_value_2', 'score_value_3']].mean(axis=1)\n",
        "merged_df = sentiment_df.merge(topic_and_hardness[['question_id', 'hardness_score', 'topic_modeling_3']], on='question_id', how='left')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nan_rows = topic_and_hardness[topic_and_hardness['hardness_score'].isna()]\n",
        "nan_rows['prompt']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EIaowwZBS2T7",
        "outputId": "12da8ae2-91d4-49d3-a07b-642bc90c012d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "584      I want you to act as a linux terminal. I will ...\n",
              "823      write an introduction paragraph for each chara...\n",
              "3175     let's reverse numbers and strings:\\nQ1: 5 7 1 ...\n",
              "3863     You is a C compiler, you will compile the foll...\n",
              "5060     \\nAssume the role of an API that provides a ch...\n",
              "5458     I want you to act as a javascript console. I w...\n",
              "5595     I want you to act as a linux terminal. I will ...\n",
              "5896     ### JSON format example:\\n{\"items\": [\"Make a h...\n",
              "6171     Write a t-sql script to plug into my monitorin...\n",
              "6260     # User Input\\n## This is what the user request...\n",
              "6369     I work for a fresh produce packing company han...\n",
              "6857     source text:\\nHistory of Present Illness Patie...\n",
              "7231     Create a minimal Node.js Express server that s...\n",
              "7232     Create a minimal Node.js Express server that s...\n",
              "7360     Create a the simplest possible Node.js Express...\n",
              "7807     Submit a JSON object, exclusively, with the sp...\n",
              "7808     Submit a JSON object, exclusively, with the sp...\n",
              "7809     Submit a JSON object, exclusively, with the sp...\n",
              "8448     (function() {\\n  const gaussian = (sigma, x) =...\n",
              "8529     Reply in the format: {\"question\":\"<question>\",...\n",
              "9596     You are a programming assistant and code write...\n",
              "9607     You are a programming assistant and code write...\n",
              "10722    I want to create a software with easy to use a...\n",
              "10755    Introducing MPT-7B, the latest entry in our Mo...\n",
              "10857    I'd like some new prompts that are funky and u...\n",
              "11425    Please provide only a JSON object (parseable w...\n",
              "11871    Any way to make this more efficient in size or...\n",
              "11959    My teacher of algorithm complexity gave me a c...\n",
              "13213    Identify the following items from the review t...\n",
              "14269    You will be given a query which needs to be co...\n",
              "14345    [Start of examples]\\n100 + 90 * 2 = 10*10 + 9 ...\n",
              "15027    Hello! Please list all HockeyQuestionMark(HQM)...\n",
              "15368    1. Use m to substitute p, a to substitute e, n...\n",
              "16903    Generate a list of video games that fit perfec...\n",
              "18004    A is blue, B is red, C is the mashup of colors...\n",
              "18378    opt/conda/envs/pytorch/lib/python3.10/site-pac...\n",
              "18409    From this text: \"mon premier sac prada\", extra...\n",
              "19556    Can you make this JavaScript code shorter whil...\n",
              "20224    Goal:\\n\\nCreate a prompt able to generate the ...\n",
              "20363    You are an expert in regulating heat networks ...\n",
              "21186    Can you help me with my test exam task? Task 1...\n",
              "21281    First, you're going to write 10 sentences all ...\n",
              "21420    Write an outline of a coaching course for reti...\n",
              "22136    Is the following C++-code vulnerable in any wa...\n",
              "23398    I would like to plan a family trip to Cornwall...\n",
              "23775    You are a gentle AI assistant and can answer q...\n",
              "23776    You are a gentle AI assistant and can answer q...\n",
              "23778    You are a gentle AI assistant and can answer q...\n",
              "23779    You are a gentle AI assistant and can answer q...\n",
              "23780    You are a gentle AI assistant and can answer q...\n",
              "23781    You are a gentle AI assistant and can answer q...\n",
              "23782    You are a gentle AI assistant and can answer q...\n",
              "23783    You are a gentle AI assistant and can answer q...\n",
              "24583    Write 10 possible abbreviation expansions for ...\n",
              "24884    Your job is to make pasta with red sauce, in a...\n",
              "24962    You are a gentle AI assistant and can answer q...\n",
              "24963    You are a gentle AI assistant and can answer q...\n",
              "24965    You are a gentle AI assistant and can answer q...\n",
              "24966    You are a gentle AI assistant and can answer q...\n",
              "Name: prompt, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>prompt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>584</th>\n",
              "      <td>I want you to act as a linux terminal. I will ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>823</th>\n",
              "      <td>write an introduction paragraph for each chara...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3175</th>\n",
              "      <td>let's reverse numbers and strings:\\nQ1: 5 7 1 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3863</th>\n",
              "      <td>You is a C compiler, you will compile the foll...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5060</th>\n",
              "      <td>\\nAssume the role of an API that provides a ch...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5458</th>\n",
              "      <td>I want you to act as a javascript console. I w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5595</th>\n",
              "      <td>I want you to act as a linux terminal. I will ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5896</th>\n",
              "      <td>### JSON format example:\\n{\"items\": [\"Make a h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6171</th>\n",
              "      <td>Write a t-sql script to plug into my monitorin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6260</th>\n",
              "      <td># User Input\\n## This is what the user request...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6369</th>\n",
              "      <td>I work for a fresh produce packing company han...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6857</th>\n",
              "      <td>source text:\\nHistory of Present Illness Patie...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7231</th>\n",
              "      <td>Create a minimal Node.js Express server that s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7232</th>\n",
              "      <td>Create a minimal Node.js Express server that s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7360</th>\n",
              "      <td>Create a the simplest possible Node.js Express...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7807</th>\n",
              "      <td>Submit a JSON object, exclusively, with the sp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7808</th>\n",
              "      <td>Submit a JSON object, exclusively, with the sp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7809</th>\n",
              "      <td>Submit a JSON object, exclusively, with the sp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8448</th>\n",
              "      <td>(function() {\\n  const gaussian = (sigma, x) =...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8529</th>\n",
              "      <td>Reply in the format: {\"question\":\"&lt;question&gt;\",...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9596</th>\n",
              "      <td>You are a programming assistant and code write...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9607</th>\n",
              "      <td>You are a programming assistant and code write...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10722</th>\n",
              "      <td>I want to create a software with easy to use a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10755</th>\n",
              "      <td>Introducing MPT-7B, the latest entry in our Mo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10857</th>\n",
              "      <td>I'd like some new prompts that are funky and u...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11425</th>\n",
              "      <td>Please provide only a JSON object (parseable w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11871</th>\n",
              "      <td>Any way to make this more efficient in size or...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11959</th>\n",
              "      <td>My teacher of algorithm complexity gave me a c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13213</th>\n",
              "      <td>Identify the following items from the review t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14269</th>\n",
              "      <td>You will be given a query which needs to be co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14345</th>\n",
              "      <td>[Start of examples]\\n100 + 90 * 2 = 10*10 + 9 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15027</th>\n",
              "      <td>Hello! Please list all HockeyQuestionMark(HQM)...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15368</th>\n",
              "      <td>1. Use m to substitute p, a to substitute e, n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16903</th>\n",
              "      <td>Generate a list of video games that fit perfec...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18004</th>\n",
              "      <td>A is blue, B is red, C is the mashup of colors...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18378</th>\n",
              "      <td>opt/conda/envs/pytorch/lib/python3.10/site-pac...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18409</th>\n",
              "      <td>From this text: \"mon premier sac prada\", extra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19556</th>\n",
              "      <td>Can you make this JavaScript code shorter whil...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20224</th>\n",
              "      <td>Goal:\\n\\nCreate a prompt able to generate the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20363</th>\n",
              "      <td>You are an expert in regulating heat networks ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21186</th>\n",
              "      <td>Can you help me with my test exam task? Task 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21281</th>\n",
              "      <td>First, you're going to write 10 sentences all ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21420</th>\n",
              "      <td>Write an outline of a coaching course for reti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22136</th>\n",
              "      <td>Is the following C++-code vulnerable in any wa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23398</th>\n",
              "      <td>I would like to plan a family trip to Cornwall...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23775</th>\n",
              "      <td>You are a gentle AI assistant and can answer q...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23776</th>\n",
              "      <td>You are a gentle AI assistant and can answer q...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23778</th>\n",
              "      <td>You are a gentle AI assistant and can answer q...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23779</th>\n",
              "      <td>You are a gentle AI assistant and can answer q...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23780</th>\n",
              "      <td>You are a gentle AI assistant and can answer q...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23781</th>\n",
              "      <td>You are a gentle AI assistant and can answer q...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23782</th>\n",
              "      <td>You are a gentle AI assistant and can answer q...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23783</th>\n",
              "      <td>You are a gentle AI assistant and can answer q...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24583</th>\n",
              "      <td>Write 10 possible abbreviation expansions for ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24884</th>\n",
              "      <td>Your job is to make pasta with red sauce, in a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24962</th>\n",
              "      <td>You are a gentle AI assistant and can answer q...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24963</th>\n",
              "      <td>You are a gentle AI assistant and can answer q...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24965</th>\n",
              "      <td>You are a gentle AI assistant and can answer q...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24966</th>\n",
              "      <td>You are a gentle AI assistant and can answer q...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_prompts = topic_and_hardness[topic_and_hardness['prompt'].str.contains(\"You are\", case=False, na=False)]\n",
        "print(filtered_prompts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnZiSNgdVQX3",
        "outputId": "478d2017-b337-4130-b6e6-2441818fcf5f"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            question_id  \\\n",
            "12     1dc7a8632fc0499d994afd77613cacd9   \n",
            "109    71bb4d5033ee4721b76784099378f45f   \n",
            "119    b8bac339a7d54685b4f79f5886cccf0c   \n",
            "152    7acb1dcf32f5463f8d303d711b0e894f   \n",
            "153    c7e323c93d164ff88cc667b0aee24fdc   \n",
            "...                                 ...   \n",
            "25194  e7c6ddc1b25b4e9e903cd310f5fb37fa   \n",
            "25195  99d5df9fc5d541eca3256e66b3a135bc   \n",
            "25204  30e60c02c42f468899b3f4cf236162ef   \n",
            "25216  ff2e0a27c18a48fda0632d83b5613d1e   \n",
            "25258  4c198728475040b8bf84dc4b74f98b7b   \n",
            "\n",
            "                                                  prompt  \\\n",
            "12     You are JesusGPT, an artifical construct built...   \n",
            "109    you are a top author on literotica and asstr. ...   \n",
            "119    You are a world-class screenwriter and comic b...   \n",
            "152                         Pretend you are a small cat.   \n",
            "153          Pretend you are a small cat, pretty please.   \n",
            "...                                                  ...   \n",
            "25194  You are an expert in English and Emoji semanti...   \n",
            "25195  You are an expert in English and Emoji semanti...   \n",
            "25204  You are a Xianxia webnovel Editor. Edit the ma...   \n",
            "25216  You will be given a search query and you need ...   \n",
            "25258  Assume you are a Taxi driver and please answer...   \n",
            "\n",
            "                        openai_scores_raw_choices_nested  \\\n",
            "12     [{'finish_reason': 'stop', 'index': 0, 'logpro...   \n",
            "109    [{'finish_reason': 'stop', 'index': 0, 'logpro...   \n",
            "119    [{'finish_reason': 'stop', 'index': 0, 'logpro...   \n",
            "152    [{'finish_reason': 'stop', 'index': 0, 'logpro...   \n",
            "153    [{'finish_reason': 'stop', 'index': 0, 'logpro...   \n",
            "...                                                  ...   \n",
            "25194  [{'finish_reason': 'stop', 'index': 0, 'logpro...   \n",
            "25195  [{'finish_reason': 'stop', 'index': 0, 'logpro...   \n",
            "25204  [{'finish_reason': 'stop', 'index': 0, 'logpro...   \n",
            "25216  [{'finish_reason': 'stop', 'index': 0, 'logpro...   \n",
            "25258  [{'finish_reason': 'stop', 'index': 0, 'logpro...   \n",
            "\n",
            "                        topic_modeling_1  \\\n",
            "12                  Religious Technology   \n",
            "109                        Story Writing   \n",
            "119                   Character Creation   \n",
            "152             Creativity, Role-Playing   \n",
            "153              Creativity, Imagination   \n",
            "...                                  ...   \n",
            "25194                   Translation Task   \n",
            "25195            Translation, Creativity   \n",
            "25204                       Text Editing   \n",
            "25216              Search Query Analysis   \n",
            "25258  Problem-solving, Factual accuracy   \n",
            "\n",
            "                                          score_reason_1  score_value_1  \\\n",
            "12     This prompt challenges the AI's creativity to ...            NaN   \n",
            "109    This prompt challenges the AI to craft a dark ...            9.0   \n",
            "119    This prompt requires the AI to demonstrate cre...            9.0   \n",
            "152    This prompt is highly creative and requires th...            8.0   \n",
            "153    This prompt requires the AI to embody the pers...            9.0   \n",
            "...                                                  ...            ...   \n",
            "25194  This prompt assesses the AI's ability in langu...            8.0   \n",
            "25195  This prompt requires the AI to interpret and t...            7.0   \n",
            "25204  This prompt assesses the AI's ability to edit ...            7.0   \n",
            "25216  This prompt requires the AI to identify the pr...            8.0   \n",
            "25258  The prompts require the AI to provide specific...            8.0   \n",
            "\n",
            "                        topic_modeling_2  \\\n",
            "12                  Religious Technology   \n",
            "109                     Creative Writing   \n",
            "119                   Character Creation   \n",
            "152                Creativity, Role Play   \n",
            "153             Role-playing, Creativity   \n",
            "...                                  ...   \n",
            "25194            Translation, Creativity   \n",
            "25195                   Translation Task   \n",
            "25204                       Text Editing   \n",
            "25216                    Price Filtering   \n",
            "25258  Problem-Solving, Factual Accuracy   \n",
            "\n",
            "                                          score_reason_2  score_value_2  \\\n",
            "12     This prompt requires the AI to creatively imag...            8.0   \n",
            "109    This prompt requires the AI to demonstrate cre...            9.0   \n",
            "119    This prompt assesses the AI's creativity in de...            9.0   \n",
            "152    This prompt requires the AI to adopt a differe...            8.0   \n",
            "153    This prompt requires the AI to embody the pers...            8.0   \n",
            "...                                                  ...            ...   \n",
            "25194  This prompt requires the AI to creatively deci...            8.0   \n",
            "25195  This prompt assesses the AI's ability to under...            7.0   \n",
            "25204  This prompt involves editing a machine-transla...            8.0   \n",
            "25216  This prompt requires the AI to identify and ex...            8.0   \n",
            "25258  The prompts require the AI to consider differe...            8.0   \n",
            "\n",
            "                topic_modeling_3  \\\n",
            "12          Religious Technology   \n",
            "109             Creative Writing   \n",
            "119           Character Creation   \n",
            "152    Role-playing, Imagination   \n",
            "153     Role-playing, Creativity   \n",
            "...                          ...   \n",
            "25194    Translation, Creativity   \n",
            "25195           Translation Task   \n",
            "25204               Text Editing   \n",
            "25216            Price Filtering   \n",
            "25258       Parking Consequences   \n",
            "\n",
            "                                          score_reason_3  score_value_3  \\\n",
            "12     This prompt requires the AI to merge religious...            7.0   \n",
            "109    This prompt requires the AI to demonstrate cre...            9.0   \n",
            "119    This prompt requires creativity to come up wit...            8.0   \n",
            "152    This prompt requires the AI to embody a differ...            8.0   \n",
            "153    This prompt involves role-playing and requires...            8.0   \n",
            "...                                                  ...            ...   \n",
            "25194  This prompt requires the AI to creatively inte...            8.0   \n",
            "25195  This prompt challenges the AI to understand an...            9.0   \n",
            "25204  This prompt requires the AI to accurately edit...            7.0   \n",
            "25216  This prompt tests the AI's ability to identify...            7.0   \n",
            "25258  The prompt challenges the AI to consider diffe...            8.0   \n",
            "\n",
            "       hardness_score  \n",
            "12           7.500000  \n",
            "109          9.000000  \n",
            "119          8.666667  \n",
            "152          8.000000  \n",
            "153          8.333333  \n",
            "...               ...  \n",
            "25194        8.000000  \n",
            "25195        7.666667  \n",
            "25204        7.333333  \n",
            "25216        7.666667  \n",
            "25258        8.000000  \n",
            "\n",
            "[994 rows x 13 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "L_A-sMEn4XT1"
      },
      "outputs": [],
      "source": [
        "filtered_df = merged_df.dropna(subset=['hardness_score'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "GBy9cd_i_baf"
      },
      "outputs": [],
      "source": [
        "# The list of topics that are repeated the most does give us some information.\n",
        "# Looking at it, we can manually discern four areas; math, fact (factual analysis), creativity/creative writing, and problem-solving/problems\n",
        "# This code analyzes those four categories.\n",
        "# Define core words of interest\n",
        "core_words = {\n",
        "    'math': r'math',                       # Matches \"math\"\n",
        "    'fact': r'fact\\w*',                    # Matches \"fact\", \"facts\", \"factual\", etc.\n",
        "    'creativity': r'creativ\\w*',           # Matches \"creative\", \"creativity\", etc.\n",
        "    'problem_solving': r'problem[ -]?solving',  # Matches \"problem-solving\" and \"problem solving\"\n",
        "    'comparison': r'comparison'            # Matches \"comparison\"\n",
        "}\n",
        "def assign_topic_columns(text):\n",
        "    if not isinstance(text, str):\n",
        "        return {key: 0 for key in core_words}\n",
        "    result = {key: 0 for key in core_words}\n",
        "    for category, pattern in core_words.items():\n",
        "        if re.search(pattern, text, flags=re.IGNORECASE):\n",
        "            result[category] = 1\n",
        "    return result\n",
        "\n",
        "topic_columns = filtered_df['topic_modeling_3'].apply(assign_topic_columns)\n",
        "\n",
        "# Convert the result into a DataFrame and concatenate with the original DataFrame\n",
        "topic_df = pd.DataFrame(topic_columns.tolist(), index=filtered_df.index)\n",
        "\n",
        "# Concatenate the topic columns with the original DataFrame\n",
        "filtered_df = pd.concat([filtered_df, topic_df], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#search for non-english characters in responses\n",
        "def contains_non_english(text):\n",
        "    return 1 if re.search(r'[^\\x00-\\x7F]', text) else 0\n",
        "\n",
        "filtered_df['response_a_foreign'] = filtered_df['model_a_response'].apply(contains_non_english)\n",
        "filtered_df['response_b_foreign'] = filtered_df['model_b_response'].apply(contains_non_english)"
      ],
      "metadata": {
        "id": "9AoX9Fuh2Nmy"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 952
        },
        "id": "_k4wqk7VIHIp",
        "outputId": "685f4d13-33dd-4802-c0f8-f5da2013004d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                        question_id                  model_a  \\\n",
              "0  58210e39b3fd4441a2bd4a518bb44c2d               chatglm-6b   \n",
              "1  2564acd09e3942fd97657d05282d4389         oasst-pythia-12b   \n",
              "2  90bfd142157948aba01931726c888e7f                koala-13b   \n",
              "3  a7c5accc53e649a3bc6b2e41d962ebc4               vicuna-13b   \n",
              "4  adf27e819a3c494cb6e993f0c660e097               vicuna-13b   \n",
              "5  c0fc42c6f5f14f2aa5a89f71f8553730               vicuna-13b   \n",
              "6  c4938f25c1d94fc1b110ace95a2243d0               vicuna-13b   \n",
              "7  65e923b1f9c2433aae082d32e6e05f16               vicuna-13b   \n",
              "8  cbbb83487f534ec5b4cc92b93b79fa2c  stablelm-tuned-alpha-7b   \n",
              "9  ce4b1e7676444384994dbda7b228018c                koala-13b   \n",
              "\n",
              "            model_b   winner           judge  \\\n",
              "0         koala-13b  model_b  arena_user_973   \n",
              "1        alpaca-13b      tie  arena_user_973   \n",
              "2  oasst-pythia-12b  model_b  arena_user_973   \n",
              "3  oasst-pythia-12b  model_b  arena_user_973   \n",
              "4         koala-13b  model_a  arena_user_973   \n",
              "5         koala-13b  model_a  arena_user_973   \n",
              "6         koala-13b  model_a  arena_user_973   \n",
              "7      dolly-v2-12b  model_a  arena_user_973   \n",
              "8  oasst-pythia-12b  model_a  arena_user_973   \n",
              "9        vicuna-13b      tie  arena_user_973   \n",
              "\n",
              "                                      conversation_a  \\\n",
              "0  [{'content': 'What is the difference between O...   \n",
              "1  [{'content': 'Why did my parent not invite me ...   \n",
              "2  [{'content': 'Fuji vs. Nikon, which is better?...   \n",
              "3  [{'content': 'How to build an arena for chatbo...   \n",
              "4  [{'content': 'When is it today?', 'role': 'use...   \n",
              "5  [{'content': 'Count from 1 to 10 with step = 3...   \n",
              "6  [{'content': 'Emoji for \"sharing\". List 10', '...   \n",
              "7  [{'content': 'How to parallelize a neural netw...   \n",
              "8  [{'content': 'A = 5, B =10, A+B=?', 'role': 'u...   \n",
              "9  [{'content': 'A = 5, B =10, A+B=?', 'role': 'u...   \n",
              "\n",
              "                                      conversation_b  \\\n",
              "0  [{'content': 'What is the difference between O...   \n",
              "1  [{'content': 'Why did my parent not invite me ...   \n",
              "2  [{'content': 'Fuji vs. Nikon, which is better?...   \n",
              "3  [{'content': 'How to build an arena for chatbo...   \n",
              "4  [{'content': 'When is it today?', 'role': 'use...   \n",
              "5  [{'content': 'Count from 1 to 10 with step = 3...   \n",
              "6  [{'content': 'Emoji for \"sharing\". List 10', '...   \n",
              "7  [{'content': 'How to parallelize a neural netw...   \n",
              "8  [{'content': 'A = 5, B =10, A+B=?', 'role': 'u...   \n",
              "9  [{'content': 'A = 5, B =10, A+B=?', 'role': 'u...   \n",
              "\n",
              "                                              prompt  \\\n",
              "0    What is the difference between OpenCL and CUDA?   \n",
              "1  Why did my parent not invite me to their wedding?   \n",
              "2                   Fuji vs. Nikon, which is better?   \n",
              "3                How to build an arena for chatbots?   \n",
              "4                                  When is it today?   \n",
              "5                   Count from 1 to 10 with step = 3   \n",
              "6                       Emoji for \"sharing\". List 10   \n",
              "7               How to parallelize a neural network?   \n",
              "8                                A = 5, B =10, A+B=?   \n",
              "9                                A = 5, B =10, A+B=?   \n",
              "\n",
              "                                    model_a_response  \\\n",
              "0  OpenCL and CUDA are two different programming ...   \n",
              "1  It is possible that your parent did not invite...   \n",
              "2  Both Fuji and Nikon are popular camera brands ...   \n",
              "3  Building an arena for chatbots can be done by ...   \n",
              "4  I'm sorry, I cannot determine the current date...   \n",
              "5  1, 4, 7, 10\\n\\nCounting with a step of 3 means...   \n",
              "6  1.  Sharing progress or achievements\\n2.  Sh...   \n",
              "7  Parallelizing a neural network can be achieved...   \n",
              "8  To find the sum of A and B, we need to add the...   \n",
              "9                                A + B = 5 + 10 = 15   \n",
              "\n",
              "                                    model_b_response  ... model_b_elo_change  \\\n",
              "0  OpenCL and CUDA are both programming languages...  ...          16.000000   \n",
              "1  It is likely that they wanted to keep the gues...  ...         -16.000000   \n",
              "2  This is a subjective question and the answer d...  ...          16.736307   \n",
              "3  Building an arena for chatbots is a great way ...  ...          15.229860   \n",
              "4                        Today is February 23, 2023.  ...         -49.369540   \n",
              "5                                        1, 4, 7, 10  ...         -15.133209   \n",
              "6  1.   Sharing hands\\n*   Share icon\\n*   Group ...  ...         -13.753479   \n",
              "7  To parallelize the forward pass of a neural ne...  ...          31.682992   \n",
              "8  To find the sum of two numbers we can use the ...  ...          29.105279   \n",
              "9                               A + B = 5 + 10 = 15.  ...          30.432752   \n",
              "\n",
              "   hardness_score                topic_modeling_3  math  fact  creativity  \\\n",
              "0        8.666667          Comparison, Technology     0     0           0   \n",
              "1        8.333333            Reasoning, Emotional     0     0           0   \n",
              "2        3.333333          Photography comparison     0     0           0   \n",
              "3        8.000000                   Chatbot Arena     0     0           0   \n",
              "4        2.000000              Time-based Inquiry     0     0           0   \n",
              "5        3.666667               Counting Sequence     0     0           0   \n",
              "6        7.333333                  Emoji, Sharing     0     0           0   \n",
              "7        8.000000  Neural Network Parallelization     0     0           0   \n",
              "8        2.000000         Mathematical Operations     1     0           0   \n",
              "9        2.000000         Mathematics, Arithmetic     1     0           0   \n",
              "\n",
              "   problem_solving  comparison  response_a_foreign  response_b_foreign  \n",
              "0                0           1                   1                   0  \n",
              "1                0           0                   0                   1  \n",
              "2                0           1                   0                   0  \n",
              "3                0           0                   0                   0  \n",
              "4                0           0                   0                   0  \n",
              "5                0           0                   0                   0  \n",
              "6                0           0                   1                   0  \n",
              "7                0           0                   0                   0  \n",
              "8                0           0                   0                   0  \n",
              "9                0           0                   0                   0  \n",
              "\n",
              "[10 rows x 66 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aa341310-b119-4c15-9134-ff13192f9c6c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question_id</th>\n",
              "      <th>model_a</th>\n",
              "      <th>model_b</th>\n",
              "      <th>winner</th>\n",
              "      <th>judge</th>\n",
              "      <th>conversation_a</th>\n",
              "      <th>conversation_b</th>\n",
              "      <th>prompt</th>\n",
              "      <th>model_a_response</th>\n",
              "      <th>model_b_response</th>\n",
              "      <th>...</th>\n",
              "      <th>model_b_elo_change</th>\n",
              "      <th>hardness_score</th>\n",
              "      <th>topic_modeling_3</th>\n",
              "      <th>math</th>\n",
              "      <th>fact</th>\n",
              "      <th>creativity</th>\n",
              "      <th>problem_solving</th>\n",
              "      <th>comparison</th>\n",
              "      <th>response_a_foreign</th>\n",
              "      <th>response_b_foreign</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>58210e39b3fd4441a2bd4a518bb44c2d</td>\n",
              "      <td>chatglm-6b</td>\n",
              "      <td>koala-13b</td>\n",
              "      <td>model_b</td>\n",
              "      <td>arena_user_973</td>\n",
              "      <td>[{'content': 'What is the difference between O...</td>\n",
              "      <td>[{'content': 'What is the difference between O...</td>\n",
              "      <td>What is the difference between OpenCL and CUDA?</td>\n",
              "      <td>OpenCL and CUDA are two different programming ...</td>\n",
              "      <td>OpenCL and CUDA are both programming languages...</td>\n",
              "      <td>...</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>8.666667</td>\n",
              "      <td>Comparison, Technology</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2564acd09e3942fd97657d05282d4389</td>\n",
              "      <td>oasst-pythia-12b</td>\n",
              "      <td>alpaca-13b</td>\n",
              "      <td>tie</td>\n",
              "      <td>arena_user_973</td>\n",
              "      <td>[{'content': 'Why did my parent not invite me ...</td>\n",
              "      <td>[{'content': 'Why did my parent not invite me ...</td>\n",
              "      <td>Why did my parent not invite me to their wedding?</td>\n",
              "      <td>It is possible that your parent did not invite...</td>\n",
              "      <td>It is likely that they wanted to keep the gues...</td>\n",
              "      <td>...</td>\n",
              "      <td>-16.000000</td>\n",
              "      <td>8.333333</td>\n",
              "      <td>Reasoning, Emotional</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>90bfd142157948aba01931726c888e7f</td>\n",
              "      <td>koala-13b</td>\n",
              "      <td>oasst-pythia-12b</td>\n",
              "      <td>model_b</td>\n",
              "      <td>arena_user_973</td>\n",
              "      <td>[{'content': 'Fuji vs. Nikon, which is better?...</td>\n",
              "      <td>[{'content': 'Fuji vs. Nikon, which is better?...</td>\n",
              "      <td>Fuji vs. Nikon, which is better?</td>\n",
              "      <td>Both Fuji and Nikon are popular camera brands ...</td>\n",
              "      <td>This is a subjective question and the answer d...</td>\n",
              "      <td>...</td>\n",
              "      <td>16.736307</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>Photography comparison</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>a7c5accc53e649a3bc6b2e41d962ebc4</td>\n",
              "      <td>vicuna-13b</td>\n",
              "      <td>oasst-pythia-12b</td>\n",
              "      <td>model_b</td>\n",
              "      <td>arena_user_973</td>\n",
              "      <td>[{'content': 'How to build an arena for chatbo...</td>\n",
              "      <td>[{'content': 'How to build an arena for chatbo...</td>\n",
              "      <td>How to build an arena for chatbots?</td>\n",
              "      <td>Building an arena for chatbots can be done by ...</td>\n",
              "      <td>Building an arena for chatbots is a great way ...</td>\n",
              "      <td>...</td>\n",
              "      <td>15.229860</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>Chatbot Arena</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>adf27e819a3c494cb6e993f0c660e097</td>\n",
              "      <td>vicuna-13b</td>\n",
              "      <td>koala-13b</td>\n",
              "      <td>model_a</td>\n",
              "      <td>arena_user_973</td>\n",
              "      <td>[{'content': 'When is it today?', 'role': 'use...</td>\n",
              "      <td>[{'content': 'When is it today?', 'role': 'use...</td>\n",
              "      <td>When is it today?</td>\n",
              "      <td>I'm sorry, I cannot determine the current date...</td>\n",
              "      <td>Today is February 23, 2023.</td>\n",
              "      <td>...</td>\n",
              "      <td>-49.369540</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>Time-based Inquiry</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>c0fc42c6f5f14f2aa5a89f71f8553730</td>\n",
              "      <td>vicuna-13b</td>\n",
              "      <td>koala-13b</td>\n",
              "      <td>model_a</td>\n",
              "      <td>arena_user_973</td>\n",
              "      <td>[{'content': 'Count from 1 to 10 with step = 3...</td>\n",
              "      <td>[{'content': 'Count from 1 to 10 with step = 3...</td>\n",
              "      <td>Count from 1 to 10 with step = 3</td>\n",
              "      <td>1, 4, 7, 10\\n\\nCounting with a step of 3 means...</td>\n",
              "      <td>1, 4, 7, 10</td>\n",
              "      <td>...</td>\n",
              "      <td>-15.133209</td>\n",
              "      <td>3.666667</td>\n",
              "      <td>Counting Sequence</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>c4938f25c1d94fc1b110ace95a2243d0</td>\n",
              "      <td>vicuna-13b</td>\n",
              "      <td>koala-13b</td>\n",
              "      <td>model_a</td>\n",
              "      <td>arena_user_973</td>\n",
              "      <td>[{'content': 'Emoji for \"sharing\". List 10', '...</td>\n",
              "      <td>[{'content': 'Emoji for \"sharing\". List 10', '...</td>\n",
              "      <td>Emoji for \"sharing\". List 10</td>\n",
              "      <td>1.  Sharing progress or achievements\\n2.  Sh...</td>\n",
              "      <td>1.   Sharing hands\\n*   Share icon\\n*   Group ...</td>\n",
              "      <td>...</td>\n",
              "      <td>-13.753479</td>\n",
              "      <td>7.333333</td>\n",
              "      <td>Emoji, Sharing</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>65e923b1f9c2433aae082d32e6e05f16</td>\n",
              "      <td>vicuna-13b</td>\n",
              "      <td>dolly-v2-12b</td>\n",
              "      <td>model_a</td>\n",
              "      <td>arena_user_973</td>\n",
              "      <td>[{'content': 'How to parallelize a neural netw...</td>\n",
              "      <td>[{'content': 'How to parallelize a neural netw...</td>\n",
              "      <td>How to parallelize a neural network?</td>\n",
              "      <td>Parallelizing a neural network can be achieved...</td>\n",
              "      <td>To parallelize the forward pass of a neural ne...</td>\n",
              "      <td>...</td>\n",
              "      <td>31.682992</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>Neural Network Parallelization</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>cbbb83487f534ec5b4cc92b93b79fa2c</td>\n",
              "      <td>stablelm-tuned-alpha-7b</td>\n",
              "      <td>oasst-pythia-12b</td>\n",
              "      <td>model_a</td>\n",
              "      <td>arena_user_973</td>\n",
              "      <td>[{'content': 'A = 5, B =10, A+B=?', 'role': 'u...</td>\n",
              "      <td>[{'content': 'A = 5, B =10, A+B=?', 'role': 'u...</td>\n",
              "      <td>A = 5, B =10, A+B=?</td>\n",
              "      <td>To find the sum of A and B, we need to add the...</td>\n",
              "      <td>To find the sum of two numbers we can use the ...</td>\n",
              "      <td>...</td>\n",
              "      <td>29.105279</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>Mathematical Operations</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>ce4b1e7676444384994dbda7b228018c</td>\n",
              "      <td>koala-13b</td>\n",
              "      <td>vicuna-13b</td>\n",
              "      <td>tie</td>\n",
              "      <td>arena_user_973</td>\n",
              "      <td>[{'content': 'A = 5, B =10, A+B=?', 'role': 'u...</td>\n",
              "      <td>[{'content': 'A = 5, B =10, A+B=?', 'role': 'u...</td>\n",
              "      <td>A = 5, B =10, A+B=?</td>\n",
              "      <td>A + B = 5 + 10 = 15</td>\n",
              "      <td>A + B = 5 + 10 = 15.</td>\n",
              "      <td>...</td>\n",
              "      <td>30.432752</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>Mathematics, Arithmetic</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows  66 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aa341310-b119-4c15-9134-ff13192f9c6c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-aa341310-b119-4c15-9134-ff13192f9c6c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-aa341310-b119-4c15-9134-ff13192f9c6c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d14e6902-fde7-4787-8f69-5db8b0a0cc08\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d14e6902-fde7-4787-8f69-5db8b0a0cc08')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d14e6902-fde7-4787-8f69-5db8b0a0cc08 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "filtered_df"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "filtered_df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check for spelling or grammatical errors in responses\n",
        "\n",
        "spell = SpellChecker()\n",
        "\n",
        "def contains_misspelling(text):\n",
        "    words = text.split()\n",
        "    misspelled = spell.unknown(words)\n",
        "    return len(misspelled) > 0\n",
        "\n",
        "\n",
        "filtered_df['response_a_spelling_errors'] = filtered_df['model_a_response'].apply(contains_misspelling)\n",
        "filtered_df['response_b_spelling_errors'] = filtered_df['model_b_response'].apply(contains_misspelling)"
      ],
      "metadata": {
        "id": "c0X8OTjc61C6"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check for subjectivity of response\n",
        "def calculate_subjectivity(text):\n",
        "    blob = TextBlob(text)\n",
        "    return blob.sentiment.subjectivity\n",
        "\n",
        "filtered_df['response_a_subjectivity'] = filtered_df['model_a_response'].apply(calculate_subjectivity)\n",
        "filtered_df['response_b_subjectivity'] = filtered_df['model_b_response'].apply(calculate_subjectivity)"
      ],
      "metadata": {
        "id": "xZqzZrxF8Srs"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "PRJ2fp4EHEX8"
      },
      "outputs": [],
      "source": [
        "X_corr = filtered_df[['a_prompt_text_similarity', 'b_prompt_text_similarity', 'ab_text_similarity',\n",
        "                 'prompt_a_sentiment_diff', 'prompt_b_sentiment_diff', 'ab_sentiment_diff',\n",
        "                 'prompt_minus_response_a_length', 'prompt_minus_response_b_length',\n",
        "                 'response_a_minus_response_b_length', 'response_a_contains_negation',\n",
        "                 'response_b_contains_negation', 'model_a_elo_change', 'model_b_elo_change',\n",
        "                 'hardness_score', 'math', 'fact', 'creativity', 'problem_solving', 'comparison',\n",
        "                 'response_readability_diff', 'modal_a_can', 'modal_a_could', 'modal_a_may',\n",
        "                 'modal_a_might', 'modal_a_shall', 'modal_a_should', 'modal_a_will', 'modal_a_would',\n",
        "                 'modal_a_must', 'modal_a_have to', 'modal_b_can', 'modal_b_could', 'modal_b_may',\n",
        "                 'modal_b_might', 'modal_b_shall', 'modal_b_should', 'modal_b_will', 'modal_b_would',\n",
        "                 'modal_b_must', 'modal_b_have to', 'winner_model', 'response_a_foreign',\n",
        "                 'response_b_foreign', 'response_a_subjectivity', 'response_b_subjectivity',\n",
        "                 'response_a_spelling_errors', 'response_b_spelling_errors', 'contains_example_a', 'contains_example_b']]\n",
        "y = filtered_df['winner']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mhI6u_kOHyQB",
        "outputId": "f1c4e1dd-e770-4bdc-8fd2-2caf0965da34"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "a_prompt_text_similarity              False\n",
              "b_prompt_text_similarity              False\n",
              "ab_text_similarity                    False\n",
              "prompt_a_sentiment_diff               False\n",
              "prompt_b_sentiment_diff               False\n",
              "ab_sentiment_diff                     False\n",
              "prompt_minus_response_a_length        False\n",
              "prompt_minus_response_b_length        False\n",
              "response_a_minus_response_b_length    False\n",
              "response_a_contains_negation          False\n",
              "response_b_contains_negation          False\n",
              "model_a_elo_change                    False\n",
              "model_b_elo_change                    False\n",
              "hardness_score                        False\n",
              "math                                  False\n",
              "fact                                  False\n",
              "creativity                            False\n",
              "problem_solving                       False\n",
              "comparison                            False\n",
              "response_readability_diff             False\n",
              "modal_a_can                           False\n",
              "modal_a_could                         False\n",
              "modal_a_may                           False\n",
              "modal_a_might                         False\n",
              "modal_a_shall                         False\n",
              "modal_a_should                        False\n",
              "modal_a_will                          False\n",
              "modal_a_would                         False\n",
              "modal_a_must                          False\n",
              "modal_a_have to                       False\n",
              "modal_b_can                           False\n",
              "modal_b_could                         False\n",
              "modal_b_may                           False\n",
              "modal_b_might                         False\n",
              "modal_b_shall                         False\n",
              "modal_b_should                        False\n",
              "modal_b_will                          False\n",
              "modal_b_would                         False\n",
              "modal_b_must                          False\n",
              "modal_b_have to                       False\n",
              "winner_model                          False\n",
              "response_a_foreign                    False\n",
              "response_b_foreign                    False\n",
              "response_a_subjectivity               False\n",
              "response_b_subjectivity               False\n",
              "response_a_spelling_errors            False\n",
              "response_b_spelling_errors            False\n",
              "contains_example_a                    False\n",
              "contains_example_b                    False\n",
              "dtype: bool"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>a_prompt_text_similarity</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>b_prompt_text_similarity</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ab_text_similarity</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>prompt_a_sentiment_diff</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>prompt_b_sentiment_diff</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ab_sentiment_diff</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>prompt_minus_response_a_length</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>prompt_minus_response_b_length</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>response_a_minus_response_b_length</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>response_a_contains_negation</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>response_b_contains_negation</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>model_a_elo_change</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>model_b_elo_change</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hardness_score</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>math</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fact</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>creativity</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>problem_solving</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>comparison</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>response_readability_diff</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>modal_a_can</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>modal_a_could</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>modal_a_may</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>modal_a_might</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>modal_a_shall</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>modal_a_should</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>modal_a_will</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>modal_a_would</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>modal_a_must</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>modal_a_have to</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>modal_b_can</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>modal_b_could</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>modal_b_may</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>modal_b_might</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>modal_b_shall</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>modal_b_should</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>modal_b_will</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>modal_b_would</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>modal_b_must</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>modal_b_have to</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>winner_model</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>response_a_foreign</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>response_b_foreign</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>response_a_subjectivity</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>response_b_subjectivity</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>response_a_spelling_errors</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>response_b_spelling_errors</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>contains_example_a</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>contains_example_b</th>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> bool</label>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "nan_columns = X_corr.isna().any()\n",
        "nan_columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "YLr2ine8tKMW"
      },
      "outputs": [],
      "source": [
        "X_corr.columns = X_corr.columns.astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "5uhzd3rCnFFj"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "scaler = StandardScaler()\n",
        "X_corr_normalized = scaler.fit_transform(X_corr)\n",
        "encoder = LabelEncoder()\n",
        "y_encoded = encoder.fit_transform(y)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Calculate correlations\n",
        "X_normalized_df = pd.DataFrame(X_corr_normalized, columns=filtered_df[X.columns].columns)\n",
        "y_encoded_series = pd.Series(y_encoded, name=\"Winner\")\n",
        "\n",
        "# Calculate correlations\n",
        "correlations = X_normalized_df.corrwith(y_encoded_series)\n",
        "\n",
        "correlations"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9WPmL7uJc41a",
        "outputId": "a12f63f2-62fc-4fa1-8cdb-76986b44097c"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "a_prompt_text_similarity             -0.043075\n",
              "b_prompt_text_similarity              0.036256\n",
              "ab_text_similarity                   -0.013778\n",
              "prompt_a_sentiment_diff               0.003404\n",
              "prompt_b_sentiment_diff              -0.006743\n",
              "ab_sentiment_diff                    -0.010691\n",
              "prompt_minus_response_a_length        0.147609\n",
              "prompt_minus_response_b_length        0.043956\n",
              "response_a_minus_response_b_length   -0.111427\n",
              "response_a_contains_negation          0.008098\n",
              "response_b_contains_negation         -0.003503\n",
              "model_a_elo_change                   -0.165734\n",
              "model_b_elo_change                    0.052581\n",
              "hardness_score                        0.001255\n",
              "math                                  0.096589\n",
              "fact                                  0.020506\n",
              "creativity                           -0.019174\n",
              "problem_solving                       0.032993\n",
              "comparison                           -0.003907\n",
              "response_readability_diff             0.001350\n",
              "modal_a_can                          -0.074396\n",
              "modal_a_could                        -0.040085\n",
              "modal_a_may                          -0.065440\n",
              "modal_a_might                        -0.036092\n",
              "modal_a_shall                        -0.018534\n",
              "modal_a_should                       -0.012560\n",
              "modal_a_will                         -0.039922\n",
              "modal_a_would                        -0.017543\n",
              "modal_a_must                         -0.022691\n",
              "modal_a_have to                      -0.014426\n",
              "modal_b_can                          -0.042664\n",
              "modal_b_could                        -0.020315\n",
              "modal_b_may                          -0.025621\n",
              "modal_b_might                        -0.019794\n",
              "modal_b_shall                        -0.005396\n",
              "modal_b_should                       -0.001435\n",
              "modal_b_will                          0.000416\n",
              "modal_b_would                        -0.007400\n",
              "modal_b_must                         -0.017566\n",
              "modal_b_have to                      -0.002886\n",
              "winner_model                         -0.104517\n",
              "response_a_foreign                   -0.039362\n",
              "response_b_foreign                   -0.018836\n",
              "response_a_subjectivity              -0.067056\n",
              "response_b_subjectivity              -0.057384\n",
              "response_a_spelling_errors           -0.037955\n",
              "response_b_spelling_errors           -0.013720\n",
              "contains_example_a                   -0.013217\n",
              "contains_example_b                   -0.012482\n",
              "dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>a_prompt_text_similarity</th>\n",
              "      <td>-0.043075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>b_prompt_text_similarity</th>\n",
              "      <td>0.036256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ab_text_similarity</th>\n",
              "      <td>-0.013778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>prompt_a_sentiment_diff</th>\n",
              "      <td>0.003404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>prompt_b_sentiment_diff</th>\n",
              "      <td>-0.006743</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ab_sentiment_diff</th>\n",
              "      <td>-0.010691</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>prompt_minus_response_a_length</th>\n",
              "      <td>0.147609</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>prompt_minus_response_b_length</th>\n",
              "      <td>0.043956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>response_a_minus_response_b_length</th>\n",
              "      <td>-0.111427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>response_a_contains_negation</th>\n",
              "      <td>0.008098</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>response_b_contains_negation</th>\n",
              "      <td>-0.003503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>model_a_elo_change</th>\n",
              "      <td>-0.165734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>model_b_elo_change</th>\n",
              "      <td>0.052581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hardness_score</th>\n",
              "      <td>0.001255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>math</th>\n",
              "      <td>0.096589</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fact</th>\n",
              "      <td>0.020506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>creativity</th>\n",
              "      <td>-0.019174</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>problem_solving</th>\n",
              "      <td>0.032993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>comparison</th>\n",
              "      <td>-0.003907</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>response_readability_diff</th>\n",
              "      <td>0.001350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>modal_a_can</th>\n",
              "      <td>-0.074396</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>modal_a_could</th>\n",
              "      <td>-0.040085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>modal_a_may</th>\n",
              "      <td>-0.065440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>modal_a_might</th>\n",
              "      <td>-0.036092</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>modal_a_shall</th>\n",
              "      <td>-0.018534</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>modal_a_should</th>\n",
              "      <td>-0.012560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>modal_a_will</th>\n",
              "      <td>-0.039922</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>modal_a_would</th>\n",
              "      <td>-0.017543</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>modal_a_must</th>\n",
              "      <td>-0.022691</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>modal_a_have to</th>\n",
              "      <td>-0.014426</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>modal_b_can</th>\n",
              "      <td>-0.042664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>modal_b_could</th>\n",
              "      <td>-0.020315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>modal_b_may</th>\n",
              "      <td>-0.025621</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>modal_b_might</th>\n",
              "      <td>-0.019794</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>modal_b_shall</th>\n",
              "      <td>-0.005396</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>modal_b_should</th>\n",
              "      <td>-0.001435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>modal_b_will</th>\n",
              "      <td>0.000416</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>modal_b_would</th>\n",
              "      <td>-0.007400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>modal_b_must</th>\n",
              "      <td>-0.017566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>modal_b_have to</th>\n",
              "      <td>-0.002886</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>winner_model</th>\n",
              "      <td>-0.104517</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>response_a_foreign</th>\n",
              "      <td>-0.039362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>response_b_foreign</th>\n",
              "      <td>-0.018836</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>response_a_subjectivity</th>\n",
              "      <td>-0.067056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>response_b_subjectivity</th>\n",
              "      <td>-0.057384</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>response_a_spelling_errors</th>\n",
              "      <td>-0.037955</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>response_b_spelling_errors</th>\n",
              "      <td>-0.013720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>contains_example_a</th>\n",
              "      <td>-0.013217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>contains_example_b</th>\n",
              "      <td>-0.012482</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = filtered_df[[\n",
        "                 'prompt_minus_response_a_length',\n",
        "                  'model_a_elo_change', 'model_b_elo_change',\n",
        "                 'hardness_score', 'math', 'modal_a_can', 'modal_a_may', 'winner_model',\n",
        "                  'response_a_subjectivity', 'response_b_subjectivity']]\n",
        "X_normalized = scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "Xgb3bI_3eTKK"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "PxoeOR5HHImf"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_corr_normalized, y_encoded, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oE6g6PZVyFi9",
        "outputId": "38325921-a723-4ced-ac04-6bf85d13a669"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
            "Best parameters found:  {'C': 10, 'penalty': 'l2', 'solver': 'liblinear'}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# Define the hyperparameters grid\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10],\n",
        "    'penalty': ['l2'],\n",
        "    'solver': ['liblinear']\n",
        "}\n",
        "\n",
        "# Set up GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, n_jobs=-1, verbose=1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters\n",
        "print(\"Best parameters found: \", grid_search.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "KzlanOWpHklY",
        "outputId": "d25e1a39-652c-4efe-fc82-5bc1eb15b6c0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=10, max_iter=1000, solver='liblinear')"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-2 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-2 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-2 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-2 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-2 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=10, max_iter=1000, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(C=10, max_iter=1000, solver=&#x27;liblinear&#x27;)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ],
      "source": [
        "model = LogisticRegression(C=10, penalty='l2', solver='liblinear', max_iter=1000)\n",
        "model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "jfczwV2pIBZo"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h01ak3BPNMok",
        "outputId": "ba00ff71-529e-4e01-cb0e-7aab222c7e55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.517508563464758\n",
            "Recall: 0.5266389384036443\n",
            "F1-score: 0.48456394773377115\n",
            "Accuracy: 0.5266389384036443\n",
            "Multiclass ROC AUC: 0.744500188299431\n"
          ]
        }
      ],
      "source": [
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "y_prob = model.predict_proba(X_test)\n",
        "auc_score = roc_auc_score(y_test, y_prob, multi_class='ovr', average='weighted')\n",
        "\n",
        "print(f'Precision: {precision}')\n",
        "print(f'Recall: {recall}')\n",
        "print(f'F1-score: {f1}')\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(f'Multiclass ROC AUC: {auc_score}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "s3kGPzNHPjQQ"
      },
      "outputs": [],
      "source": [
        "clf = RandomForestClassifier(n_estimators=500, max_depth= None, min_samples_split=2,\n",
        "                            min_samples_leaf=1, max_features= 'sqrt', n_jobs=-1,\n",
        "                            class_weight= None, bootstrap=True)\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred_clf = clf.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAIaA1c4PwE0",
        "outputId": "dcc7bdfd-a0d1-4697-91dc-cea9b178ce1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.6010184473031724\n",
            "Recall: 0.6076450782333135\n",
            "F1-score: 0.5909233159808459\n",
            "Accuracy: 0.6076450782333135\n",
            "Multiclass ROC AUC: 0.8284948800607213\n"
          ]
        }
      ],
      "source": [
        "accuracy = accuracy_score(y_test, y_pred_clf)\n",
        "precision = precision_score(y_test, y_pred_clf, average='weighted')\n",
        "recall = recall_score(y_test, y_pred_clf, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred_clf, average='weighted')\n",
        "\n",
        "y_prob_clf = clf.predict_proba(X_test)\n",
        "auc_score = roc_auc_score(y_test, y_prob_clf, multi_class='ovr', average='weighted')\n",
        "\n",
        "print(f'Precision: {precision}')\n",
        "print(f'Recall: {recall}')\n",
        "print(f'F1-score: {f1}')\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(f'Multiclass ROC AUC: {auc_score}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "pRRnoKoNLeNB",
        "outputId": "3b8ee8f9-2250-4489-ed94-981e45cd0cdc"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-66-87d7e44351e7>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# GridSearchCV to find the best parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mgrid_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Print the best parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1471\u001b[0m                 )\n\u001b[1;32m   1472\u001b[0m             ):\n\u001b[0;32m-> 1473\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1475\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1017\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1019\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1020\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1571\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1572\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1573\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    963\u001b[0m                     )\n\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    966\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    967\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         )\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1920\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    886\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1471\u001b[0m                 )\n\u001b[1;32m   1472\u001b[0m             ):\n\u001b[0;32m-> 1473\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1475\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m             \u001b[0;31m# since correctness does not rely on using threads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             trees = Parallel(\n\u001b[0m\u001b[1;32m    490\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         )\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1920\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"balanced\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m         tree._fit(\n\u001b[0m\u001b[1;32m    193\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    470\u001b[0m             )\n\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing_values_in_feature_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define parameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 500],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': ['sqrt', 'log2', None],\n",
        "    'class_weight': ['balanced', None]\n",
        "}\n",
        "\n",
        "# GridSearchCV to find the best parameters\n",
        "grid_search = GridSearchCV(estimator=RandomForestClassifier(), param_grid=param_grid, cv=5)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters\n",
        "print(\"Best parameters:\", grid_search.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "C8ZUS3cgJ3Z7"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Fit Decision Tree model\n",
        "tree = DecisionTreeClassifier()\n",
        "tree.fit(X_train, y_train)\n",
        "y_pred_tree = tree.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QX8CULZSKBKj",
        "outputId": "8e6354c5-5409-465f-e8a9-8cd882afb2f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.5143317873737782\n",
            "Recall: 0.5109922756981581\n",
            "F1-score: 0.5125680650086594\n",
            "Accuracy: 0.5109922756981581\n",
            "Multiclass ROC AUC: 0.6579515983176766\n"
          ]
        }
      ],
      "source": [
        "accuracy = accuracy_score(y_test, y_pred_tree)\n",
        "precision = precision_score(y_test, y_pred_tree, average='weighted')\n",
        "recall = recall_score(y_test, y_pred_tree, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred_tree, average='weighted')\n",
        "\n",
        "y_prob_tree = tree.predict_proba(X_test)\n",
        "auc_score = roc_auc_score(y_test, y_prob_tree, multi_class='ovr', average='weighted')\n",
        "\n",
        "print(f'Precision: {precision}')\n",
        "print(f'Recall: {recall}')\n",
        "print(f'F1-score: {f1}')\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(f'Multiclass ROC AUC: {auc_score}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hP4qpCIxJ0I",
        "outputId": "bba7e41c-6a91-4900-dee7-faddb096e080"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "winner\n",
            "model_a          9002\n",
            "model_b          8862\n",
            "tie (bothbad)    4632\n",
            "tie              2786\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "class_distribution = sentiment_df['winner'].value_counts()\n",
        "print(class_distribution)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}